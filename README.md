# ğŸ§  Image Captioning & Segmentation Web App

This is a simple and complete project that performs **Image Captioning** and **Image Segmentation** using deep learning. It features a **Streamlit web interface** where users can upload an image and get both a descriptive caption and segmented visual results.

---

## ğŸ“Œ Features
- âœ¨ Generate descriptive **captions** using a pretrained **BLIP** model
- ğŸŸ© Perform **object detection and segmentation** using **Mask R-CNN**
- ğŸ¯ Web-based interface with **Streamlit**
- âš¡ Easy to run, even on CPU â€” no model training needed

---

## ğŸ–¼ï¸ Example Output
**Input:** ![](example_input.jpg)

**Caption:** *"A dog catching a frisbee in the park."*

**Segmented Output:** ![](example_segmented.jpg)

---

## ğŸ› ï¸ Tech Stack
- Python
- Streamlit
- HuggingFace Transformers (`BLIP`)
- PyTorch (`Mask R-CNN` from torchvision)
- OpenCV & PIL

---

## ğŸ“‚ Project Structure
```bash
image_captioning_segmentation/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ captioning/
â”‚   â””â”€â”€ caption_model.py
â”œâ”€â”€ segmentation/
â”‚   â””â”€â”€ mask_rcnn.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/YOUR_USERNAME/image-captioning-segmentation.git
cd image-captioning-segmentation
```

### 2. Create Virtual Environment (optional but recommended)
```bash
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # macOS/Linux
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the App
```bash
streamlit run app/app.py
```

---

## ğŸ“¦ Dependencies
```txt
streamlit
torch
torchvision
transformers
Pillow
opencv-python

## CREDITS
Pranav Shahapure 
